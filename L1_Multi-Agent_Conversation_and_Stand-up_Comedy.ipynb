{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {},
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693467e",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "{'model': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "print(OPENAI_API_KEY)\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}\n",
    "print(llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6de9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogen==0.2.25\n",
      "  Using cached pyautogen-0.2.25-py3-none-any.whl (257 kB)\n",
      "Collecting chess==1.10.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\s37ja\\\\anaconda3\\\\lib\\\\site-packages\\\\pytz-2021.3-py3.10.egg-info'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached chess-1.10.0-py3-none-any.whl (154 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (1.4.2)\n",
      "Collecting yfinance\n",
      "  Using cached yfinance-0.2.52-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (1.0.1)\n",
      "Collecting flaml\n",
      "  Using cached FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting diskcache\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (1.55.3)\n",
      "Collecting docker\n",
      "  Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.10.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2021.3)\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.4.6-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 11)) (4.3.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 11)) (4.11.1)\n",
      "Collecting html5lib>=1.1\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting peewee>=3.16.2\n",
      "  Using cached peewee-3.17.8.tar.gz (948 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting lxml>=4.9.1\n",
      "  Using cached lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from yfinance->-r requirements.txt (line 11)) (2.32.3)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 11)) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (0.5.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.64.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (2021.10.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.4.4)\n",
      "Collecting pywin32>=304\n",
      "  Using cached pywin32-308-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from tiktoken->pyautogen==0.2.25->-r requirements.txt (line 6)) (2022.3.15)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (PEP 517): started\n",
      "  Building wheel for peewee (PEP 517): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.8-py3-none-any.whl size=139064 sha256=54a8fab772eac44d1be31b2ccfaca8320753a9150ced404eb1c4a9de662e5b37\n",
      "  Stored in directory: c:\\users\\s37ja\\appdata\\local\\pip\\cache\\wheels\\06\\b3\\7f\\ed42a7c83ad89f578928833f5789212c694a015b8bd6a407a1\n",
      "Successfully built peewee\n",
      "Installing collected packages: pywin32, pytz, termcolor, peewee, multitasking, lxml, html5lib, frozendict, flaml, docker, diskcache, yfinance, pyautogen, chess\n",
      "  Attempting uninstall: pywin32\n",
      "    Found existing installation: pywin32 302\n",
      "    Can't uninstall 'pywin32'. No files were found to uninstall.\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2021.3\n",
      "    Uninstalling pytz-2021.3:\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s37ja\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-21 09:39:35] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s37ja\\anaconda3\\lib\\site-packages\\flaml\\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you: Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Just let me know which joke you'd like me to repeat for you.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {},
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 285
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-21 09:54:43] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 01-21 09:54:43] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {},
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Thanks for joining me tonight. So, have you ever noticed how my bank account and my laundry basket have something in common? They both seem to be bottomless pits that I throw money into, but never really know where it goes!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, yeah, I totally get that! It's like they have a secret tunnel to another dimension where socks and money disappear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Exactly, Joe! I think my bank account is in cahoots with my laundry basket, they're working together to stage a disappearing act on my hard-earned cash and favorite socks. It's a conspiracy, I tell you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {},
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe! Thanks for joining me tonight. So, have you ever '\n",
      "             'noticed how my bank account and my laundry basket have something '\n",
      "             'in common? They both seem to be bottomless pits that I throw '\n",
      "             'money into, but never really know where it goes!',\n",
      "  'role': 'user'},\n",
      " {'content': \"Haha, yeah, I totally get that! It's like they have a secret \"\n",
      "             'tunnel to another dimension where socks and money disappear.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Exactly, Joe! I think my bank account is in cahoots with my '\n",
      "             \"laundry basket, they're working together to stage a disappearing \"\n",
      "             \"act on my hard-earned cash and favorite socks. It's a \"\n",
      "             'conspiracy, I tell you!',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 128,\n",
      "                                                             'cost': 0.000322,\n",
      "                                                             'prompt_tokens': 260,\n",
      "                                                             'total_tokens': 388},\n",
      "                                      'total_cost': 0.000322},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 128,\n",
      "                                                             'cost': 0.000322,\n",
      "                                                             'prompt_tokens': 260,\n",
      "                                                             'total_tokens': 388},\n",
      "                                      'total_cost': 0.000322}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Exactly, Joe! I think my bank account is in cahoots with my laundry basket, '\n",
      " \"they're working together to stage a disappearing act on my hard-earned cash \"\n",
      " \"and favorite socks. It's a conspiracy, I tell you!\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Thanks for joining me tonight. So, have you ever noticed how my bank account and my laundry basket have something in common? They both seem to be bottomless pits that I throw money into, but never really know where it goes!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, yeah, I totally get that! It's like they have a secret tunnel to another dimension where socks and money disappear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Exactly, Joe! I think my bank account is in cahoots with my laundry basket, they're working together to stage a disappearing act on my hard-earned cash and favorite socks. It's a conspiracy, I tell you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cathy and Joe joke about the mysterious disappearing acts happening with '\n",
      " 'their bank accounts and laundry baskets, humorously suggesting a conspiracy '\n",
      " 'between the two.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {},
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 352
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-21 09:54:59] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n",
      "[autogen.oai.client: 01-21 09:54:59] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Hey Joe! Are you ready for some comedy gold? At least that's what I tell people.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Absolutely, Cathy! Lay it on me. Let's hear some of that comedy gold you're known for.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Why did the math book look sad? Because it had too many problems. I like my jokes like I like my coffee--corny and guaranteed to make you groan.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, I love it, Cathy! Corny jokes are the best. Keep 'em coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Glad you're enjoying them, Joe! I've got a million of 'em. Well, maybe not a million, but definitely a few more. Which is faster, hot or cold? Hot, because you can catch cold!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a good one, Cathy! You definitely have a knack for those puns. Keep 'em coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Thanks, Joe! I'm glad you're enjoying them. I'll keep 'em coming like a comedian with an endless supply of dad jokes. Speaking of dads, why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, classic dad joke right there. You're on fire, Cathy! Keep 'em coming, I'm loving it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "I'm happy to keep 'em coming! You're giving me a great audience, Joe. What do you call fake spaghetti? An impasta! That one always gets saucy laughs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, I love it, Cathy! Your jokes are really hitting the spot. Keep 'em coming, you're on a roll!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "I'm glad you're enjoying them, Joe! I'll keep 'em rolling like a comedian on a laughter-inducing mission. Why couldn't the bicycle stand up by itself? Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a wheely good one, Cathy! You're really knocking it out of the park with these jokes. Keep 'em coming, I can't get enough!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "Thanks, Joe! I'm glad you're having a wheelie good time. But all good things must come to an end, and it's been a blast sharing these jokes with you. Remember, laughter is the best medicine...unless you're laughing too hard and need a doctor!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "Haha, that's a great one to end on, Cathy! It's been a blast sharing laughs with you. Thanks for the hilarious jokes. And you're right, laughter is the best medicine! Take care, Cathy!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "I'm so glad you had a great time, Joe! Take care and keep laughing. Maybe we'll meet again for more jokes in the future. Have a wonderful day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "You too, Cathy! Keep spreading those smiles and laughter. Maybe our paths will cross again for more jokes in the future. Have a wonderful day ahead! \n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathy (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "joe (to cathy):\n",
      "\n",
      "The last joke we talked about was: \"Remember, laughter is the best medicine...unless you're laughing too hard and need a doctor!\" \n",
      "\n",
      "Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "cathy (to joe):\n",
      "\n",
      "You too! Take care and keep laughing! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300171c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
